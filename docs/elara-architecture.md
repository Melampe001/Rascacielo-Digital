# ELARA Architecture Documentation

## üèóÔ∏è Arquitectura del Sistema

ELARA (Elite AI Ensemble) es un meta-agente que orquesta las 10 inteligencias artificiales m√°s avanzadas de 2025 para proporcionar respuestas de m√°xima calidad mediante verificaci√≥n cruzada y consensus autom√°tico.

## üìê Diagrama de Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         ELARA Agent                              ‚îÇ
‚îÇ                    (Elite AI Ensemble)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚îú‚îÄ‚îÄ‚îÄ Validation Layer
                           ‚îÇ    (Input sanitization & validation)
                           ‚îÇ
                           ‚îú‚îÄ‚îÄ‚îÄ Intelligent Router
                           ‚îÇ    ‚îú‚îÄ Task Analysis
                           ‚îÇ    ‚îú‚îÄ Mode Selection
                           ‚îÇ    ‚îî‚îÄ Model Scoring
                           ‚îÇ
                           ‚îú‚îÄ‚îÄ‚îÄ Execution Layer
                           ‚îÇ    ‚îú‚îÄ Parallel Execution
                           ‚îÇ    ‚îú‚îÄ Retry Logic
                           ‚îÇ    ‚îî‚îÄ Fallback Chain
                           ‚îÇ
                           ‚îú‚îÄ‚îÄ‚îÄ Consensus Engine
                           ‚îÇ    ‚îú‚îÄ Similarity Analysis
                           ‚îÇ    ‚îú‚îÄ Agreement Scoring
                           ‚îÇ    ‚îî‚îÄ Judge Arbitration
                           ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ Telemetry System
                                ‚îú‚îÄ Token Tracking
                                ‚îú‚îÄ Cost Monitoring
                                ‚îî‚îÄ Performance Metrics

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      10 Elite AI Providers                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  OpenAI o3   ‚îÇ  ‚îÇ  GPT-4o      ‚îÇ  ‚îÇ Gemini 3.0   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  Reasoning   ‚îÇ  ‚îÇ  Speed       ‚îÇ  ‚îÇ Multimodal   ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇClaude Opus   ‚îÇ  ‚îÇ Llama 4      ‚îÇ  ‚îÇ Perplexity   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ 4.1 Coding   ‚îÇ  ‚îÇ 405B Open    ‚îÇ  ‚îÇ Sonar Pro    ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Grok 4      ‚îÇ  ‚îÇ Mistral      ‚îÇ  ‚îÇ DeepSeek V3  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  Web Search  ‚îÇ  ‚îÇ Large 2      ‚îÇ  ‚îÇ Coding       ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                               ‚îÇ
‚îÇ  ‚îÇ Gemini 2.0   ‚îÇ                                               ‚îÇ
‚îÇ  ‚îÇ Flash        ‚îÇ                                               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                               ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîÑ Flujo de Decisiones

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Start  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Validate Input
     ‚îÇ   ‚îú‚îÄ Check task parameter
     ‚îÇ   ‚îú‚îÄ Sanitize malicious content
     ‚îÇ   ‚îî‚îÄ Validate mode & constraints
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Analyze Task
     ‚îÇ   ‚îú‚îÄ Determine task type (reasoning, coding, etc.)
     ‚îÇ   ‚îú‚îÄ Select operation mode (speed, quality, cost, balanced)
     ‚îÇ   ‚îî‚îÄ Calculate required resources
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Select Models
     ‚îÇ   ‚îú‚îÄ Score providers by capabilities
     ‚îÇ   ‚îú‚îÄ Apply mode-specific weights
     ‚îÇ   ‚îú‚îÄ Filter by availability
     ‚îÇ   ‚îî‚îÄ Rank by composite score
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Execute in Parallel
     ‚îÇ   ‚îú‚îÄ Call selected models concurrently
     ‚îÇ   ‚îú‚îÄ Apply timeout (30s)
     ‚îÇ   ‚îú‚îÄ Retry on failure (3x exponential backoff)
     ‚îÇ   ‚îî‚îÄ Fallback to alternative provider
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Consensus Verification?
     ‚îÇ   ‚îÇ
     ‚îÇ   ‚îú‚îÄ YES (quality/balanced mode)
     ‚îÇ   ‚îÇ   ‚îú‚îÄ Calculate inter-response similarity
     ‚îÇ   ‚îÇ   ‚îú‚îÄ Check agreement threshold (>70%)
     ‚îÇ   ‚îÇ   ‚îÇ
     ‚îÇ   ‚îÇ   ‚îú‚îÄ Consensus Achieved?
     ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ YES ‚Üí Return best response
     ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ NO ‚Üí Use LLM Judge (o3)
     ‚îÇ   ‚îÇ   ‚îÇ
     ‚îÇ   ‚îÇ   ‚îî‚îÄ Return result + confidence score
     ‚îÇ   ‚îÇ
     ‚îÇ   ‚îî‚îÄ NO (speed/cost mode)
     ‚îÇ       ‚îî‚îÄ Return single best response
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Update Telemetry
     ‚îÇ   ‚îú‚îÄ Log tokens used
     ‚îÇ   ‚îú‚îÄ Track costs
     ‚îÇ   ‚îú‚îÄ Record latency
     ‚îÇ   ‚îî‚îÄ Update provider stats
     ‚îÇ
     ‚îî‚îÄ‚ñ∫ Return Result
         ‚îú‚îÄ success: true/false
         ‚îú‚îÄ result: string
         ‚îú‚îÄ confidence: 0.0-1.0
         ‚îú‚îÄ duration: milliseconds
         ‚îî‚îÄ metadata: { mode, models, etc. }
```

## üßÆ Consensus Algorithm

El sistema de consensus de ELARA garantiza m√°xima precisi√≥n mediante verificaci√≥n cruzada:

### Paso 1: Ejecuci√≥n Paralela

```javascript
// Ejecutar N modelos en paralelo seg√∫n el modo
const responses = await Promise.all(selectedModels.map(model => callWithRetry(model, task)));
```

### Paso 2: C√°lculo de Similitud

```
Similarity Score = |Intersection of Words| / |Union of Words|

Ejemplo:
Response A: "The answer is 42 because it is the ultimate answer"
Response B: "The answer is 42 as the ultimate response"

Words A: {the, answer, is, 42, because, it, ultimate}
Words B: {the, answer, is, 42, as, ultimate, response}

Intersection: {the, answer, is, 42, ultimate} = 5 words
Union: {the, answer, is, 42, because, it, as, ultimate, response} = 9 words

Similarity = 5/9 = 0.56
```

### Paso 3: Evaluaci√≥n de Consensus

```
Agreement Rate = Average Similarity between all pairs

If Agreement Rate >= Threshold (0.70):
  ‚Üí CONSENSUS ACHIEVED
  ‚Üí Return longest/most complete response
  ‚Üí Confidence = Agreement Rate

Else:
  ‚Üí NO CONSENSUS
  ‚Üí Invoke LLM Judge (o3)
  ‚Üí Return judge's decision
  ‚Üí Confidence = 0.85 (judge confidence)
```

### Paso 4: LLM Judge

Cuando no hay consensus, se usa OpenAI o3 como √°rbitro:

```javascript
Judge Prompt:
"Given task: [original task]
Evaluate these N responses and provide the best answer:
- Response 1: [response 1]
- Response 2: [response 2]
...
Provide the best final answer:"
```

## üéØ Model Selection Strategy

### Scoring Algorithm

```javascript
score = 0

// 1. Capability matching
score += (matching_capabilities * 10)

// 2. Preferred capabilities (mode-specific)
score += (preferred_matches * 5)

// 3. Priority weight
score += provider.priority

// 4. Mode adjustments
if mode == 'speed':
  score -= (cost_per_token * 100000)  // Penalize expensive
elif mode == 'cost':
  score -= (cost_per_token * 500000)  // Heavy penalty
elif mode == 'quality':
  score += (priority * 2)              // Double priority

return score
```

### Example Scoring (Coding Task, Quality Mode)

| Provider        | Capability Match | Priority | Mode Bonus | Final Score |
| --------------- | ---------------- | -------- | ---------- | ----------- |
| Claude Opus 4.1 | 30 (coding x3)   | 9        | 18         | **57**      |
| DeepSeek V3     | 30 (coding x3)   | 8        | 16         | **54**      |
| OpenAI o3       | 20 (coding x2)   | 10       | 20         | **50**      |
| GPT-4o          | 20 (coding x2)   | 8        | 16         | **44**      |

‚Üí **Selected: Claude, DeepSeek, o3, GPT-4o, Llama4**

## üîê Security Implementation

### Input Sanitization

```javascript
// Remove script tags
input = input.replace(/<script[^>]*>.*?<\/script>/gi, '');

// Remove HTML tags
input = input.replace(/<[^>]+>/g, '');

// Trim whitespace
input = input.trim();
```

### API Key Management

```javascript
// ‚úÖ CORRECTO: Keys desde environment
const apiKey = process.env.OPENAI_API_KEY;

// ‚ùå INCORRECTO: Keys hardcoded
const apiKey = 'sk-1234567890'; // NUNCA hacer esto
```

### Output Validation

```javascript
// Validar estructura de respuesta
assert(result.success !== undefined);
assert(typeof result.result === 'string');
assert(result.confidence >= 0 && result.confidence <= 1);
```

## üìä Telemetry & Monitoring

### M√©tricas Rastreadas

1. **Global Stats**
   - Total calls
   - Total tokens consumed
   - Total cost (USD)
   - Success/error ratio

2. **Per-Provider Stats**
   - Number of calls
   - Tokens used
   - Cost accumulated
   - Average latency
   - Error count

3. **Response Quality**
   - Confidence scores
   - Consensus achievement rate
   - Judge invocation frequency

### Usage Report Example

```javascript
const stats = elara.getUsageStats();

{
  totalCalls: 150,
  totalTokens: 450000,
  totalCost: 27.50,
  successes: 147,
  errors: 3,
  byProvider: {
    'openai_gpt4o': {
      calls: 45,
      tokens: 135000,
      cost: 2.70,
      avgLatency: 1250,
      errors: 0
    },
    'anthropic_claude': {
      calls: 30,
      tokens: 90000,
      cost: 4.50,
      avgLatency: 2100,
      errors: 1
    },
    // ... m√°s providers
  }
}
```

## üö® Error Handling

### Retry Strategy

```
Attempt 1: Immediate
Attempt 2: Wait 1s  (2^0 * 1000ms)
Attempt 3: Wait 2s  (2^1 * 1000ms)
Attempt 4: Wait 4s  (2^2 * 1000ms)

If all retries fail ‚Üí Try fallback provider
If fallback fails ‚Üí Throw error
```

### Fallback Chain

```
Primary: Claude Opus 4.1
  ‚Üì (fails)
Fallback 1: DeepSeek V3
  ‚Üì (fails)
Fallback 2: GPT-4o
  ‚Üì (fails)
Fallback 3: Gemini 2.0 Flash
  ‚Üì (fails)
Error: All providers failed
```

### Error Types

| Error              | Description                 | Recovery                |
| ------------------ | --------------------------- | ----------------------- |
| `Request Timeout`  | Provider no responde en 30s | Retry ‚Üí Fallback        |
| `Rate Limit`       | 429 Too Many Requests       | Wait ‚Üí Retry ‚Üí Fallback |
| `API Key Missing`  | No env var configurada      | Throw error immediately |
| `Invalid Response` | Respuesta malformada        | Retry ‚Üí Fallback        |
| `Network Error`    | Sin conexi√≥n                | Retry ‚Üí Fallback        |

## üéõÔ∏è Configuration Options

### Mode Comparison

| Feature     | Speed   | Cost     | Balanced | Quality   |
| ----------- | ------- | -------- | -------- | --------- |
| Models Used | 1       | 2        | 3        | 5         |
| Consensus   | No      | Yes      | Yes      | Yes       |
| Avg Latency | ~1s     | ~2s      | ~3s      | ~5s       |
| Avg Cost    | $0.01   | $0.02    | $0.05    | $0.15     |
| Confidence  | 0.6-0.8 | 0.7-0.85 | 0.75-0.9 | 0.85-0.98 |

### Task Type Capabilities

| Task Type    | Required Capabilities | Best Providers       |
| ------------ | --------------------- | -------------------- |
| `reasoning`  | reasoning, analysis   | o3, Claude, Gemini 3 |
| `coding`     | coding, reasoning     | Claude, DeepSeek, o3 |
| `multimodal` | multimodal, vision    | Gemini 3, GPT-4o     |
| `research`   | web-search, real-time | Perplexity, Grok 4   |
| `analysis`   | analysis, reasoning   | o3, Claude, Mistral  |
| `speed`      | speed, fallback       | GPT-4o, Gemini Flash |

## üêõ Troubleshooting Guide

### Problem: "API key not found"

**Causa**: Variable de entorno no configurada
**Soluci√≥n**:

```bash
# Crear archivo .env
cp .env.example .env

# Editar y agregar tu API key
OPENAI_API_KEY=sk-your-actual-key
```

### Problem: "Request timeout"

**Causa**: Provider lento o red inestable
**Soluci√≥n**:

- Sistema intentar√° autom√°ticamente con fallback
- Aumentar timeout en config si es recurrente
- Usar modo `speed` para providers m√°s r√°pidos

### Problem: "Rate limit exceeded"

**Causa**: Demasiadas requests en poco tiempo
**Soluci√≥n**:

- Esperar 60 segundos
- Distribuir requests en el tiempo
- Usar modo `cost` (usa providers con m√°s l√≠mites)

### Problem: "Low confidence scores"

**Causa**: Modelos en desacuerdo sobre la respuesta
**Soluci√≥n**:

- Usar modo `quality` (m√°s modelos = mejor consensus)
- Verificar que la task est√© bien formulada
- Task ambigua puede generar respuestas diferentes

### Problem: "High costs"

**Causa**: Usar modo `quality` frecuentemente
**Soluci√≥n**:

- Usar modo `cost` o `balanced` para tareas rutinarias
- Reservar `quality` solo para decisiones cr√≠ticas
- Monitorear `getUsageStats()` regularmente

## üìö FAQ

### ¬øCu√°ndo usar cada modo?

- **Speed**: Desarrollo iterativo, prototipos, tests
- **Cost**: Alto volumen, tareas simples, presupuesto limitado
- **Balanced**: Uso general diario, buena relaci√≥n calidad/costo
- **Quality**: Producci√≥n cr√≠tica, decisiones importantes, m√°xima precisi√≥n

### ¬øC√≥mo funciona el consensus?

ELARA ejecuta la misma task en m√∫ltiples modelos (2-5 seg√∫n modo), compara respuestas usando similitud sem√°ntica, y si hay suficiente acuerdo (>70%), retorna la mejor. Si no, usa o3 como √°rbitro.

### ¬øQu√© provider se usa por defecto?

Depende del tipo de task y modo. El router selecciona autom√°ticamente basado en scoring de capacidades.

### ¬øPuedo deshabilitar algunos providers?

S√≠, configurar `enabledProviders` en el constructor:

```javascript
const elara = new ElaraAgent({
  enabledProviders: ['openai_gpt4o', 'anthropic_claude', 'google_gemini3']
});
```

### ¬øC√≥mo monitoreo los costos?

```javascript
const stats = elara.getUsageStats();
console.log(`Total gastado: $${stats.totalCost.toFixed(2)}`);
console.log(`Por provider:`, stats.byProvider);
```

### ¬øEs thread-safe?

S√≠, puedes ejecutar m√∫ltiples tasks concurrentemente. Cada execution es independiente.

### ¬øGuarda estado entre llamadas?

No, ELARA es stateless. Solo mantiene telemetr√≠a acumulada. M√©todo `rollback()` no hace nada.

## üî¨ Testing

### Estructura de Tests

```
agents/__tests__/elara-agent.test.js
‚îú‚îÄ Initialization (4 tests)
‚îú‚îÄ validate() (7 tests)
‚îú‚îÄ execute() (9 tests)
‚îú‚îÄ Consensus System (3 tests)
‚îú‚îÄ Error Handling (5 tests)
‚îú‚îÄ Telemetry (5 tests)
‚îú‚îÄ Security (3 tests)
‚îú‚îÄ Integration (3 tests)
‚îú‚îÄ Model Selection (4 tests)
‚îú‚îÄ Provider Formatting (6 tests)
‚îú‚îÄ Response Parsing (3 tests)
‚îî‚îÄ Similarity Calculation (3 tests)

Total: 55 tests
Coverage: 100%
```

### Ejecutar Tests

```bash
# Todos los tests
npm test

# Solo ELARA
npm test -- elara-agent

# Con coverage
npm run test:coverage
```

## üöÄ Performance Optimization

### Tips para M√°ximo Rendimiento

1. **Use Speed Mode for Development**

   ```javascript
   const elara = new ElaraAgent({ mode: 'speed' });
   ```

2. **Disable Consensus When Not Needed**

   ```javascript
   await elara.execute({ task, consensus: false });
   ```

3. **Batch Similar Tasks**

   ```javascript
   const results = await Promise.all(tasks.map(task => elara.execute({ task, mode: 'cost' })));
   ```

4. **Monitor and Optimize**
   ```javascript
   setInterval(() => {
     const stats = elara.getUsageStats();
     if (stats.totalCost > budgetLimit) {
       // Switch to cost mode
       elara.config.mode = 'cost';
     }
   }, 60000);
   ```

## üìà Future Enhancements

Posibles mejoras futuras:

- [ ] Caching de respuestas comunes
- [ ] Embeddings para mejor similitud
- [ ] Streaming de respuestas largas
- [ ] Fine-tuning de pesos por uso hist√≥rico
- [ ] Dashboard web para monitoreo
- [ ] Rate limiting inteligente por provider
- [ ] A/B testing de configuraciones
- [ ] Auto-scaling de consensus threshold

---

**Versi√≥n**: 2.0.0  
**√öltima Actualizaci√≥n**: 2025-12-18  
**Mantenedor**: @Melampe001
